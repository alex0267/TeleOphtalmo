{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fcn_for_ratio.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"v9xd4bFcEWq6","colab_type":"text"},"source":["\n","# Getting the model\n"]},{"cell_type":"code","metadata":{"id":"yuyIaC8SEWrB","colab_type":"code","outputId":"64710d05-cb06-452c-db68-846bc5ba8003","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import torch\n","model = torch.hub.load('pytorch/vision:v0.5.0', 'fcn_resnet101', pretrained=True)\n","model.eval()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.5.0\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["FCN(\n","  (backbone): IntermediateLayerGetter(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (classifier): FCNHead(\n","    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.1, inplace=False)\n","    (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (aux_classifier): FCNHead(\n","    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.1, inplace=False)\n","    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"dUqYvDF2EWrK","colab_type":"text"},"source":["All pre-trained models expect input images normalized in the same way,\n","i.e. mini-batches of 3-channel RGB images of shape `(N, 3, H, W)`, where `N` is the number of images, `H` and `W` are expected to be at least `224` pixels.\n","The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n","and `std = [0.229, 0.224, 0.225]`.\n","\n","The model returns an `OrderedDict` with two Tensors that are of the same height and width as the input Tensor, but with 21 classes.\n","`output['out']` contains the semantic masks, and `output['aux']` contains the auxillary loss values per-pixel. In inference mode, `output['aux']` is not useful.\n","So, `output['out']` is of shape `(N, 21, H, W)`. More documentation can be found [here](https://pytorch.org/docs/stable/torchvision/models.html#object-detection-instance-segmentation-and-person-keypoint-detection)."]},{"cell_type":"code","metadata":{"id":"2j_SKrzCJ5xA","colab_type":"code","outputId":"97a30296-5ad3-4622-e2a0-20c5812090f9","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1584608840349,"user_tz":-60,"elapsed":22600,"user":{"displayName":"Michael ALLOUCHE","photoUrl":"","userId":"17841023976364809532"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gViewPJUSe64","colab_type":"text"},"source":["### To load the data\n"]},{"cell_type":"code","metadata":{"id":"S0Bg-HCZSdHG","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RF4zb9UyObHb","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","from __future__ import print_function, division\n","import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchvision import transforms, utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8glGblNSh9i","colab_type":"code","colab":{}},"source":["##here put your custom destination folder\n","#arr_train_labels = np.load('drive/My Drive/Dataset_test_fcn')\n","#arr_val_labels = np.load('drive/My Drive/Lab2_DL/val_labels.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pzQTD8mN1YD","colab_type":"text"},"source":["### Input\n"]},{"cell_type":"code","metadata":{"id":"oJ-wVDQXNS18","colab_type":"code","colab":{}},"source":["# Top level data directory. Here we assume the format of the directory conforms\n","#   to the ImageFolder structure\n","data_dir = \"/content/drive/My Drive/CRP_Attali_Wu_Allouche_Bekdouche/Third Branch/Magrabia/Magrabia/MagrabiaMale\"\n","\n","# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","model_name = \"fcn_resnet101\"\n","\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 8\n","\n","# Number of epochs to train for\n","num_epochs = 15\n","\n","# Flag for feature extracting. When False, we finetune the whole model,\n","#   when True we only update the reshaped layer params\n","feature_extract = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ju_Yl72GOQ_i","colab_type":"text"},"source":["### Model Training and Validation Code"]},{"cell_type":"code","metadata":{"id":"EZT3xYy4O7xg","colab_type":"code","colab":{}},"source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OfOOIEaUPepp","colab_type":"text"},"source":["### Set Model Parameters, unfreezing layers"]},{"cell_type":"code","metadata":{"id":"6lIrFYgiJqye","colab_type":"code","colab":{}},"source":["def initialize_model(model_name, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_fcn = torch.hub.load('pytorch/vision:v0.5.0', 'fcn_resnet101', pretrained=True)\n","    set_parameter_requires_grad(model_fcn, feature_extract)\n","    num_ftrs = model_fcn.aux_classifier[4]\n","    #Here i put an output of the last layer of 2 because we want to segment into two parts, it was 21 before.\n","    model_fcn.backbone.layer4[2].conv3 = nn.Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    model_fcn.classifier[0] =  nn.Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    model_fcn.classifier[4]= nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    #model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","    input_size = 224\n","\n","    return model_fcn, input_size\n","\n","# Initialize the model for this run\n","model_fcn, input_size = initialize_model(model_name, feature_extract, use_pretrained=True)\n","model_fcn2, input_size = initialize_model(model_name, feature_extract, use_pretrained=True)\n","\n","# Print the model we just instantiated\n","#print(model_fcn)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bBajXA8VGXF-","colab_type":"text"},"source":["# Loading the data\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"knCNxBYpoBEe","colab_type":"text"},"source":["### Preprocess images\n","\n"]},{"cell_type":"code","metadata":{"id":"hCpUeKUPRcDp","colab_type":"code","colab":{}},"source":["import glob\n","import re\n","\n","from PIL import Image\n","import cv2\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jfLxYlN9NinP","colab_type":"code","colab":{}},"source":["from collections import OrderedDict\n","camvid_colors = OrderedDict([\n","    (\"main\", np.array([13, 240,231], dtype=np.uint8)),\n","    (\"in\", np.array([1,62,231], dtype=np.uint8)),\n","    (\"out\", np.array([0, 0, 0], dtype=np.uint8))])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-racjg71PucH","colab_type":"code","colab":{}},"source":["from scipy import stats\n","\n","def convert_label_to_grayscale(img):\n","    im = np.float32(img)\n","    \"\"\" \n","    for i in range(im.shape[0]) :\n","      for j in range(im.shape[1]) :\n","        rgb = im[i][j]\n","        if (not (rgb == [0,0,0]).all() ) and (not (rgb == [1,62,231]).all() ):\n","          print(rgb)\n","    \"\"\"\n","    #print(\"im\",np.unique(im))\n","    #print(im.shape)\n","    out = (np.ones(im.shape[:2]) * 2).astype(np.uint8)\n","    for gray_val, (label, rgb) in enumerate(camvid_colors.items()):\n","        #print(im == np.asarray(rgb) )\n","        match_pxls = np.where((im == np.asarray(rgb)).sum(-1) == 3)\n","        #print(match_pxls)\n","        if (gray_val == 0) :\n","          out[match_pxls] = 1\n","        else : \n","          out[match_pxls] = 0\n","    assert (out != 255).all(), \"rounding errors or missing classes in camvid_colors\"\n","    return Image.fromarray(out.astype(np.uint8))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8pNQnfAIUI8s","colab_type":"text"},"source":["### Creating the dataset"]},{"cell_type":"code","metadata":{"id":"_X_r9fpzOY7O","colab_type":"code","colab":{}},"source":["class RIGA(Dataset):\n","    \"\"\"Face Landmarks dataset.\"\"\"\n","\n","    def __init__(self, input_dir, disc_dir, cup_dir, transform=None):\n","\n","        discard_disc = [25,15,16,23,27,28,29,39,46]\n","        omit_disc = []\n","        omit_disc.append([22,47]) #1\n","        omit_disc.append([22,47]) #2\n","        omit_disc.append([22]) #3\n","        omit_disc.append([8,11,22]) #4\n","        omit_disc.append([8,11,22]) #5\n","        omit_disc.append([8,11]) #6\n","        self.input_dir = input_dir\n","        filenames = glob.glob(input_dir+'/*prime.tif')\n","        self.images_paths = []\n","        self.disc_paths = []\n","        self.cup_paths = []\n","        for image in glob.glob(input_dir+'/*prime.tif') : \n","          img_id = [int(n) for n in re.findall(r'\\d+', image)][0]\n","          if img_id not in discard_disc : \n","            for disc in glob.glob(disc_dir+'/*.png') :\n","              #print(disc) \n","              disc_idx = [int(n) for n in re.findall(r'\\d+', disc)]\n","              if (disc_idx[0] not in omit_disc[disc_idx[1]-1]) : \n","                for cup in  glob.glob(cup_dir+'/*.png') :\n","                  cup_idx = [int(n) for n in re.findall(r'\\d+', cup)]\n","                  if(cup_idx[0]==disc_idx[0]) and (cup_idx[1]==disc_idx[1]) and (cup_idx[0]==img_id) : \n","                    self.images_paths.append(image)\n","                    self.disc_paths.append(disc)\n","                    self.cup_paths.append(cup)\n","\n","\n","        i=0\n","        print(len(self.images_paths))\n","        print(len(self.disc_paths))\n","        print(len(self.cup_paths))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images_paths)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        #print(self.images_paths[idx])\n","        image = Image.open(self.images_paths[idx])\n","        disc = Image.open(self.disc_paths[idx])\n","        cup = Image.open(self.cup_paths[idx])\n","        sample = {'image': image, 'disc' : disc , 'cup' : cup}\n","        disc = convert_label_to_grayscale(disc)\n","        cup = convert_label_to_grayscale(cup)\n","        #print(np.float32(disc))\n","        #print(np.float32(disc).max(),np.float32(cup).max())\n","        if self.transform:\n","            image = self.transform(image)\n","        data_transforms =transforms.Compose([transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","\n","        disc = torch.from_numpy(cv2.resize(np.float32(disc), \n","                                           dsize=(image.size()[2],image.size()[1]), \n","                                           interpolation=cv2.INTER_NEAREST)).long() #image.size()[1],image.size()[2]\n","        cup =torch.from_numpy(cv2.resize(np.float32(cup) ,\n","                                         dsize=(image.size()[2],image.size()[1]), \n","                                         interpolation=cv2.INTER_NEAREST)).long()\n","        #print(np.float32(disc).max(),np.float32(cup).max())\n","        image = data_transforms(image)\n","        #print(np.float32(disc))\n","        return image, disc,cup"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2veMIE0UQqx","colab_type":"text"},"source":["### Create dataset, train and validation set, and preprocess the data"]},{"cell_type":"code","metadata":{"id":"vW3yg1xKQs8L","colab_type":"code","outputId":"dbe4ff24-0b4f-4894-bcdf-1ceaa62609b9","colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["\n","# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms =transforms.Compose([\n","        #transforms.ToTensor(),\n","        torchvision.transforms.Resize((input_size)),\n","        #transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","\n","\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","disc_dir = \"/content/drive/My Drive/CRP_Attali_Wu_Allouche_Bekdouche/Third Branch/Magrabia/outputs/disc_segmented\"\n","cup_dir = \"/content/drive/My Drive/CRP_Attali_Wu_Allouche_Bekdouche/Third Branch/Magrabia/outputs/cup_segmented\"\n","# Create training and validation datasets\n","image_dataset = RIGA(data_dir,disc_dir,cup_dir, data_transforms)\n","print(len(image_dataset))\n","\n","train_set, val_set = random_split(image_dataset, [200,15])\n","# Create training and validation dataloaders\n","dataloaders_dict = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initializing Datasets and Dataloaders...\n","215\n","215\n","215\n","215\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d7vBjjFUUoFr","colab_type":"text"},"source":["### Check unfreezed layers and intialize optimizer"]},{"cell_type":"code","metadata":{"id":"xEU6yYOTRS-V","colab_type":"code","outputId":"36f529bd-3b67-48ff-8dd2-1bd85295384c","colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["model_fcn = model_fcn.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_fcn.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model_fcn.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_fcn.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer = optim.Adam(params_to_update, lr=0.001)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t backbone.layer4.2.conv3.weight\n","\t classifier.0.weight\n","\t classifier.4.weight\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oByFNl_4qGSv","colab_type":"code","outputId":"31e31555-7067-4a4a-85c1-bc4ee3ac7fe2","colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["model_fcn2 = model_fcn2.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update2 = model_fcn2.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update2 = []\n","    for name,param in model_fcn2.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update2.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_fcn2.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer2 = optim.Adam(params_to_update2, lr=0.001)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t backbone.layer4.2.conv3.weight\n","\t classifier.0.weight\n","\t classifier.4.weight\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rSa0JYn8UvAE","colab_type":"text"},"source":["### Define the 2-D Cross Entropy Loss Function "]},{"cell_type":"code","metadata":{"id":"33zJYLSBLsQ_","colab_type":"code","colab":{}},"source":["import torch.nn.functional as F\n","from distutils.version import LooseVersion\n","def cross_entropy2d(input, target,device, weight=None, size_average=True):\n","    # input: (n, c, h, w), target: (n, h, w)\n","    n, c, h, w = input.size()\n","    # log_p: (n, c, h, w)\n","    if LooseVersion(torch.__version__) < LooseVersion('0.3'):\n","        # ==0.2.X\n","        log_p = F.log_softmax(input)\n","    else:\n","        # >=0.3\n","        log_p = F.log_softmax(input, dim=1)\n","    # log_p: (n*h*w, c)\n","    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous()\n","    log_p = log_p[target.view(n, h, w, 1).repeat(1, 1, 1, c) >= 0]\n","    log_p = log_p.view(-1, c)\n","    # target: (n*h*w,)\n","    mask = target >= 0\n","    target = target[mask]\n","    loss = F.nll_loss(log_p.to(device), target.to(device), weight=weight, reduction='sum')\n","    if size_average:\n","        loss /= mask.data.sum()\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hTHTWfynU1A6","colab_type":"text"},"source":["### Train the disc FCN"]},{"cell_type":"code","metadata":{"id":"gGG57z-GOQHX","colab_type":"code","colab":{}},"source":["def train_model_disc(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        model.train()  # Set model to training mode\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        # Iterate over data.\n","        for (inputs, discs, cups) in dataloaders:\n","            inputs = inputs.to(device)\n","            dics = discs.to(device)\n","            cups = discs.to(device)\n","#.permute(0,3,1,2)\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward\n","            # track history if only in train\n","            with torch.set_grad_enabled(True):\n","                # Get model outputs and calculate loss\n","                # Special case for inception because in training it has an auxiliary output. In train\n","                #   mode we calculate the loss by summing the final output and the auxiliary output\n","                #   but in testing we only consider the final output\n","                outputs = model(inputs.float())\n","                #print(type(outputs))\n","                outputs = outputs[\"out\"]\n","                outputs =  outputs.to(device)\n","                \"\"\"for k,v in outputs.items() :\n","                    print\n","                    output_disc[k] = v[:3, :, :] \n","                    output_cups[k] = v[3:, :, :]\"\"\" \n","                #print(output_disc.size(),output_cups.size())\n","                loss = cross_entropy2d(outputs, discs,device)\n","\n","                # backward + optimize only if in training phase\n","                loss.backward()\n","                optimizer.step()\n","\n","            # statistics\n","            running_loss += loss.item() * inputs.size(0)\n","\n","        epoch_loss = running_loss / len(dataloaders.dataset)\n","\n","        print('Loss: {:.4f}'.format(epoch_loss))\n","\n","        if epoch_loss < 0.001 :\n","          break \n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, running_loss\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9nk3kZz4U44j","colab_type":"text"},"source":["### Train the Cup FCN"]},{"cell_type":"code","metadata":{"id":"VrCXIuEIpeE2","colab_type":"code","colab":{}},"source":["def train_model_cup(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        model.train()  # Set model to training mode\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        # Iterate over data.\n","        for (inputs, discs, cups) in dataloaders:\n","            inputs = inputs.to(device)\n","            dics = discs.to(device)\n","            cups = discs.to(device)\n","#.permute(0,3,1,2)\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward\n","            # track history if only in train\n","            with torch.set_grad_enabled(True):\n","                # Get model outputs and calculate loss\n","                # Special case for inception because in training it has an auxiliary output. In train\n","                #   mode we calculate the loss by summing the final output and the auxiliary output\n","                #   but in testing we only consider the final output\n","                outputs = model(inputs.float())\n","                #print(type(outputs))\n","                outputs = outputs[\"out\"]\n","                outputs =  outputs.to(device)\n","                \"\"\"for k,v in outputs.items() :\n","                    print\n","                    output_disc[k] = v[:3, :, :] \n","                    output_cups[k] = v[3:, :, :]\"\"\" \n","                #print(output_disc.size(),output_cups.size())\n","                loss = cross_entropy2d(outputs, cups,device)\n","\n","                # backward + optimize only if in training phase\n","                loss.backward()\n","                optimizer.step()\n","\n","            # statistics\n","            running_loss += loss.item() * inputs.size(0)\n","\n","        epoch_loss = running_loss / len(dataloaders.dataset)\n","\n","        print('Loss: {:.4f}'.format(epoch_loss))\n","\n","        if epoch_loss < 0.001 :\n","          break \n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, running_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wJ9uWg-RTEf","colab_type":"code","colab":{}},"source":["criterion = None #nn.NLLLoss2d() #nn.CrossEntropyLoss()\n","# Train and evaluate\n","model_fcn = model_fcn.float()\n","model_fcn, hist = train_model_disc(model_fcn, dataloaders_dict, criterion, optimizer, num_epochs=20)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jnoyTOZvqkcs","colab_type":"code","colab":{}},"source":["model_fcn2 = model_fcn2.float()\n","model_fcn2, hist = train_model_cup(model_fcn2, dataloaders_dict, criterion, optimizer2, num_epochs=10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7z9OlgJVCLm","colab_type":"text"},"source":["### Save the model "]},{"cell_type":"code","metadata":{"id":"2PMOufOcopoN","colab_type":"code","colab":{}},"source":["PATH = \"FCN.model\"\n","PATH2 = \"FCN2.model\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PI5NubckonZr","colab_type":"code","colab":{}},"source":["torch.save(model_fcn.state_dict(), PATH)\n","torch.save(model_fcn2.state_dict(), PATH2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kfQSRRv2o4Dr","colab_type":"code","colab":{}},"source":["model_fcn.load_state_dict(torch.load(PATH))\n","model_fcn2.load_state_dict(torch.load(PATH2))\n","model_fcn.eval()\n","model_fcn2.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AqiR2xrSVKlP","colab_type":"text"},"source":["### Evaluate the MSE for the ratio on the model "]},{"cell_type":"code","metadata":{"id":"egMfz4yfRTKo","colab_type":"code","colab":{}},"source":["err = []\n","mse = 0\n","for (im,d,c) in val_set:\n","  im = im.to(device)\n","  d = d.to(device)\n","  c = c.to(device)\n","  with torch.no_grad():\n","    boutput = model_fcn(im.unsqueeze(0))\n","    output = boutput[\"out\"][0].argmax(0).float()\n","  with torch.no_grad():\n","    boutput2 = model_fcn2(im.unsqueeze(0))\n","    output2 = boutput2[\"out\"][0].argmax(0).float()\n","  r_pred = output2.sum()/output.sum()\n","  r = c.sum()/d.sum()\n","  print(r,r_pred,output2.sum(),output.sum(),c.sum(),d.sum())\n","  err += [(r_pred-r)**2]\n","for (im,d,c) in train_set :\n","  im = im.to(device)\n","  d = d.to(device)\n","  c = c.to(device)\n","  with torch.no_grad():\n","    boutput = model_fcn(im.unsqueeze(0))\n","    output = boutput[\"out\"][0].argmax(0).float()\n","  with torch.no_grad():\n","    boutput2 = model_fcn2(im.unsqueeze(0))\n","    output2 = boutput2[\"out\"][0].argmax(0).float()\n","  r_pred = output2.sum()/output.sum()\n","  r = c.sum()/d.sum()\n","  print(r,r_pred,output2.sum(),output.sum(),c.sum(),d.sum())\n","  err += [(r_pred-r)**2]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxY1nT-Hw_kt","colab_type":"code","outputId":"eadada9f-e1db-4cbe-eb25-e92c3be04b6d","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(sum(err)/len(err))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor(0.8898, device='cuda:0')\n"],"name":"stdout"}]}]}