# -*- coding: utf-8 -*-
"""ResNet50_First_Branch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UGTZmM90201wjotArXSpoQ3ka9WjCqQF
"""

# Mount your notebook on your gdrive
# After running the cell follow the instruction and past the key
# this is a test to commit from VSCode
from google.colab import drive
drive.mount('/content/gdrive')

"""# Libraries"""

from fastai.vision import *
import pandas as pd
import re
import csv

!pip install "torch==1.4" "torchvision==0.5.0"

"""# Paths"""

path_root = Path('gdrive/My Drive/Teleophtalmo/Data/ORIGA-20200525T213107Z-001.zip (Unzipped Files)/ORIGA/originales') # Define path to the image folders
path_glaucoma = Path(path_root, 'glaucoma/')
path_healthy = Path(path_root,'sanas/')

! ls gdrive/'My Drive'/Teleophtalmo/Data/'ORIGA-20200525T213107Z-001.zip (Unzipped Files)'/ORIGA/originales

"""# Loading Data

### Glaucoma and Healthy Eyes
"""

np.random.seed(42)

# We create labels from folders
data = ImageDataBunch.from_folder(path_root,
                                  train='.',
                                  valid_pct=0.2,
                                  ds_tfms=get_transforms(do_flip = False, flip_vert=False, max_rotate=0, p_affine=0), 
                                  size=(256,256), 
                                  num_workers=4, 
                                  bs = 16) \
                .normalize(imagenet_stats)

data.show_batch(rows=3, figsize=(8,8))

#Define the two classes
data.classes, data.c

# Lenght of train dataset
len(data.train_ds)

# Lenght of validation dataset
len(data.valid_ds)

"""# Transfer Learning - resnet50

### To save the best model
"""

class SaveBestModel(Recorder):
    def __init__(self, learn,name='best_model_01-ResNet50-02'):
        super().__init__(learn)
        self.name = name
        self.best_loss = None
        self.best_acc = None
        self.save_method = self.save_when_acc
        
    def save_when_acc(self, metrics):        
        loss, acc = metrics[0], metrics[1]
        if self.best_acc == None or acc > self.best_acc:
            self.best_acc = acc
            self.best_loss = loss
            self.learn.save(f'{self.name}')
            print("Save the best accuracy {:.5f}".format(self.best_acc))
        elif acc == self.best_acc and  loss < self.best_loss:
            self.best_loss = loss
            self.learn.save(f'{self.name}')
            print("Accuracy is eq,Save the lower loss {:.5f}".format(self.best_loss))
            
    def on_epoch_end(self,last_metrics=MetricsList,**kwargs:Any):
        self.save_method(last_metrics)

"""### **Completely Frozen model**"""

learn = cnn_learner(data, 
                    models.resnet50,       
                    metrics=accuracy)

learn.fit_one_cycle(50)

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()

"""### **Completely Unfrozen**"""

learn_unfreeze = cnn_learner(data, 
                             models.resnet50,       
                             metrics=accuracy)

learn_unfreeze.lr_find()
learn_unfreeze.recorder.plot()

learn_unfreeze.unfreeze()

learn_unfreeze.fit_one_cycle(10)

interp = ClassificationInterpretation.from_learner(learn_unfreeze)
interp.plot_confusion_matrix()

"""### **Freezing the last two layers (Classifier + last convolutional layer).**"""

learn = cnn_learner(data, 
                    models.resnet50,       
                    metrics=accuracy,callback_fns=SaveBestModel)

learn.loss_func

learn.freeze_to(-2)

learn.layer_groups

learn.fit_one_cycle(50)

learn.summary()

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()

import torch
import torch.nn as nn
from torchvision import models

original_model = models.resnet50(pretrained=True)

class ResnetFeature(nn.Module):
            def __init__(self):
                super(ResnetFeature, self).__init__()
                self.features = nn.Sequential(
                    # stop at conv4
                    *list(original_model.children())[:-1]
                   # *list(original_model.features.children())
                )
            def forward(self, x):
                x = self.features(x)
                return x

model = ResnetFeature()

model_dict = model.state_dict()
pretrained_dict = torch.load('/content/gdrive/My Drive/CRP_Attali_Wu_Allouche_Bekdouche/First_Branch/orig/models/best_model.pth',map_location=torch.device('cpu'))
# 1. filter out unnecessary keys
pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}
# 2. overwrite entries in the existing state dict
model_dict.update(pretrained_dict)
# 3. load the new state dict
model.load_state_dict(model_dict)
model.eval()

import cv2
from PIL import Image
from torchvision import transforms
def featuremap(path_image):
  print(path_image)
  img = cv2.imread(path_image)
  trans = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))
        ])
  img = trans(img)
  img = img.unsqueeze(0) 
  output = model(img)
  featuremap = output.squeeze(0)
  return featuremap

"""### Feature extraction of the whole dataset"""

# To get the images in the same order than google drive.
def sorted_alphanumeric(data):
    convert = lambda text: int(text) if text.isdigit() else text.lower()
    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] 
    return sorted(data, key=alphanum_key)

images_glaucoma = sorted_alphanumeric(os.listdir(path_glaucoma))
images_healthy = sorted_alphanumeric(os.listdir(path_healthy))

"""Glaucoma Features"""

with open('/content/gdrive/My Drive/CRP_Attali_Wu_Allouche_Bekdouche/First_Branch/orig/feature_extraction_glaucoma.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    for name in images_glaucoma:
      writer.writerow(featuremap(str(path_glaucoma)+"/"+name).detach().numpy().tolist())

"""Healthy Features"""

with open('/content/gdrive/My Drive/CRP_Attali_Wu_Allouche_Bekdouche/First_Branch/orig/feature_extraction_healthy.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    for name in images_healthy:
      writer.writerow(featuremap(str(path_healthy)+"/"+name).detach().numpy().tolist())

"""# Loading Final Dataset - Feature Extraction"""

glaucoma_feature_dataset=pd.read_csv("/content/gdrive/My Drive/CRP_Attali_Wu_Allouche_Bekdouche/First_Branch/orig/feature_extraction_glaucoma.csv", header=None)

healthy_feature_dataset=pd.read_csv("/content/gdrive/My Drive/CRP_Attali_Wu_Allouche_Bekdouche/First_Branch/orig/feature_extraction_healthy.csv", header=None)

glaucoma_feature_dataset.head()

glaucoma_feature_dataset.shape

healthy_feature_dataset.head()

healthy_feature_dataset.shape